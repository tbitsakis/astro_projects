{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy classification\n",
    "This is a ML code that performs galaxy classification using user-defined labels from the Galaxy-Zoo (http://zoo1.galaxyzoo.org/) project. \n",
    "\n",
    "The steps are the following: <br>\n",
    "1. Import libraries and sample\n",
    "2. Split sub-samples (training, validation, testing)\n",
    "3. Fit with various classifier and check performance\n",
    "4. Compare various classifiers in testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, utils, metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part we are going to upload the galaxy images. \n",
    "# For now I use a dataset of digits from scikit-learn\n",
    "# I plot some examples\n",
    "# digits = datasets.load_digits()\n",
    "# print(digits.images.reshape((len(digits.images), -1)))\n",
    "\n",
    "# images_and_labels = list(zip(digits.images, digits.target))\n",
    "# for index, (image, label) in enumerate(images_and_labels[:9]):\n",
    "#     plt.subplot(2, 9, index + 1)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#     plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we are going to use astropy to read fits images and convert them into \n",
    "# similar format matrices\n",
    "# you can also use np.matrix.flatten to flatten a matrix into a single line\n",
    "import glob\n",
    "files = glob.glob(\"data/*.npy\")\n",
    "galaxies = np.array([np.load(i) for i in files])\n",
    "labels = [file.split(\"_\")[0].strip('data/') for file in files]\n",
    "\n",
    "# Display some example images of galaxies\n",
    "images_and_labels = list(zip(galaxies, labels))\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(galaxies)\n",
    "data = galaxies.reshape((n_samples, -1))\n",
    "\n",
    "# Normalize values to maximum and setting low values to 0\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i] / max(data[i])\n",
    "\n",
    "# data[data < 0.001] = 0\n",
    "        \n",
    "# Shuffle the samples\n",
    "shuffled_indexes = np.arange(len(galaxies))\n",
    "np.random.shuffle(shuffled_indexes)\n",
    "\n",
    "data = data[shuffled_indexes]\n",
    "labels = list(np.array(labels)[shuffled_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting in training, validation, and test samples\n",
    "data_train = data[:8 * n_samples // 10] # i.e. 80% training\n",
    "labels_train = labels[:8 * n_samples // 10]\n",
    "\n",
    "data_valid = data[8 * n_samples // 10:9 * n_samples // 10] # i.e. 10% validation (80->90%)\n",
    "labels_valid = labels[8 * n_samples // 10:9 * n_samples // 10]\n",
    "\n",
    "data_test = data[9 * n_samples // 10:] # i.e. 10% testing (90->100%)\n",
    "labels_test = labels[9 * n_samples // 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Using scikit-learn / SVM classifier\n",
    "We are going to test the performance of a classical Support Vector Machines classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00         9\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "model_svc = LinearSVC()\n",
    "model_svc.fit(data_train, labels_train)\n",
    "\n",
    "# Comparisong with prediction\n",
    "predicted = model_svc.predict(data_valid)\n",
    "\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_svc, metrics.classification_report(labels_valid, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using scikit-learn / LogisticRegression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00         9\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "model_lrc = LogisticRegression()\n",
    "model_lrc.fit(data_train, labels_train)\n",
    "\n",
    "# Comparisong with prediction\n",
    "predicted = model_svc.predict(data_valid)\n",
    "\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_lrc, metrics.classification_report(labels_valid, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Using scikit-learn / Multilayer perceptron classifier\n",
    "We are going to use a simple Neural Network (Multilayer perceptron) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00         9\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "model_MLP = MLPClassifier()\n",
    "model_MLP.fit(data_train, labels_train)\n",
    "\n",
    "# Comparisong with prediction\n",
    "predicted = model_MLP.predict(data_valid)\n",
    "\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_MLP, metrics.classification_report(labels_valid, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Using scikit learn / Random Forests\n",
    "We are using a a scikit-learn bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00         9\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "model_RF = RandomForestClassifier()\n",
    "model_RF.fit(data_train, labels_train)\n",
    "\n",
    "# Comparisong with prediction\n",
    "predicted = model_RF.predict(data_valid)\n",
    "\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_RF, metrics.classification_report(labels_valid, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Using Keras simple Neural Network classifier\n",
    "We are using a simple multilayer perceptron classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data to 0-1 range\n",
    "# data = data / np.max(data[:])\n",
    "\n",
    "num_pixels = data_train.shape[1] \n",
    "\n",
    "# It is good practice to use a one hot encoding \n",
    "# of the class values (ellip, spiral), to tranform\n",
    "# the vector of class integers into a binary matrix.\n",
    "int_enc = LabelEncoder()\n",
    "labels_train_int = int_enc.fit_transform(labels_train)\n",
    "labels_valid_int = int_enc.fit_transform(labels_valid)\n",
    "labels_test_int = int_enc.fit_transform(labels_test)\n",
    "\n",
    "oh_enc = OneHotEncoder(sparse=False)\n",
    "labels_train_int = labels_train_int.reshape(len(labels_train_int), 1)\n",
    "labels_train_ohe = oh_enc.fit_transform(labels_train_int)\n",
    "labels_valid_int = labels_valid_int.reshape(len(labels_valid_int), 1)\n",
    "labels_valid_ohe = oh_enc.fit_transform(labels_valid_int)\n",
    "labels_test_int = labels_test_int.reshape(len(labels_test_int), 1)\n",
    "labels_test_ohe = oh_enc.fit_transform(labels_test_int)\n",
    "\n",
    "# uniques, labels_valid = np.unique(labels_valid, return_inverse=True)\n",
    "# labels_train_cat = np_utils.to_categorical(labels_train)\n",
    "# labels_valid_cat = np_utils.to_categorical(labels_valid)\n",
    "num_classes = labels_valid_ohe.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    sgd = optimizers.SGD(lr=0.1)\n",
    "    model_Ker = Sequential()\n",
    "    model_Ker.add(Dense(num_pixels // 3, input_dim=num_pixels, kernel_initializer='normal',activation='relu'))\n",
    "#     model_Ker.add(Dense(num_pixels // 5, input_dim=num_pixels, kernel_initializer='normal',activation='relu'))\n",
    "    model_Ker.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))#,\n",
    "                                          #kernel_regularizer=regularizers.l1(0.1)))\n",
    "    # Compile model\n",
    "    model_Ker.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model_Ker\n",
    "\n",
    "# Build the model\n",
    "model_Ker = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.1559 - acc: 0.7168 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0379 - acc: 0.9823 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0245 - acc: 0.9823 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_Ker.fit(data_train, labels_train_ohe, validation_data=(data_valid, labels_valid_ohe), \n",
    "                                            epochs=10, batch_size=20, verbose=2)\n",
    "\n",
    "# Comparisong with prediction\n",
    "predicted = model_Ker.predict(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for <keras.engine.sequential.Sequential object at 0x1243daa20>:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00         9\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Reverse one hot encoding\n",
    "pred = int_enc.inverse_transform(predicted.argmax(1))\n",
    "\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_Ker, metrics.classification_report(labels_valid, pred)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check \n",
    "Here we are using the test sample for a final check of the various algorithms used above. We check if their performance is as good as it is reported in the validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Classification report for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00        10\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0]\n",
      " [ 0  5]] \n",
      "\n",
      "====================================================================================\n",
      "Classification report for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00        10\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0]\n",
      " [ 0  5]] \n",
      "\n",
      "====================================================================================\n",
      "Classification report for MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00        10\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0]\n",
      " [ 0  5]] \n",
      "\n",
      "====================================================================================\n",
      "Classification report for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00        10\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0]\n",
      " [ 0  5]] \n",
      "\n",
      "====================================================================================\n",
      "Classification report for <keras.engine.sequential.Sequential object at 0x1243daa20>:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ellip       1.00      1.00      1.00        10\n",
      "     spiral       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0]\n",
      " [ 0  5]] \n",
      "\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"====================================================================================\")\n",
    "# Predictions for SVM\n",
    "predicted = model_svc.predict(data_test)\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_svc, metrics.classification_report(labels_test, predicted)))\n",
    "print(\"Confusion matrix:\\n%s \\n\" % metrics.confusion_matrix(labels_test, predicted))\n",
    "print(\"====================================================================================\")\n",
    "\n",
    "# Predictions for LogisticRegression\n",
    "predicted = model_svc.predict(data_test)\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_lrc, metrics.classification_report(labels_test, predicted)))\n",
    "print(\"Confusion matrix:\\n%s \\n\" % metrics.confusion_matrix(labels_test, predicted))\n",
    "print(\"====================================================================================\")\n",
    "\n",
    "# Predictions for MLP\n",
    "predicted = model_MLP.predict(data_test)\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_MLP, metrics.classification_report(labels_test, predicted)))\n",
    "print(\"Confusion matrix:\\n%s \\n\" % metrics.confusion_matrix(labels_test, predicted))\n",
    "print(\"====================================================================================\")\n",
    "\n",
    "# Predictions for RandomForests\n",
    "predicted = model_RF.predict(data_test)\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_RF, metrics.classification_report(labels_test, predicted)))\n",
    "print(\"Confusion matrix:\\n%s \\n\" % metrics.confusion_matrix(labels_test, predicted))\n",
    "print(\"====================================================================================\")\n",
    "\n",
    "# Predictions for Keras Neural Network\n",
    "predicted = model_Ker.predict(data_test)\n",
    "pred = int_enc.inverse_transform(predicted.argmax(1))\n",
    "print(\"Classification report for %s:\\n%s\\n\"\n",
    "      % (model_Ker, metrics.classification_report(labels_test, pred)))\n",
    "print(\"Confusion matrix:\\n%s \\n\" % metrics.confusion_matrix(labels_test, pred))\n",
    "print(\"====================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
